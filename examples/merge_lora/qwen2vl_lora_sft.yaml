### Note: DO NOT use quantized model or quantization_bit when merging lora adapters

# ### model
# model_name_or_path: /mnt/workspace/xiaoxi/model_pretrained/qwen_lab/Qwen2-VL-7B-Instruct
# adapter_name_or_path: /mnt/workspace/xiaoxi/xiaoxi-all/model_logs/vllm_factory/qwen2_vl-7b/lora/sft_vocot_grounding_2024_11_11_11_23_22
# template: qwen2_vl
# finetuning_type: lora

# ### export
# export_dir: /mnt/workspace/xiaoxi/xiaoxi-all/model_logs/vllm_factory/qwen2_vl-7b/lora/qwen2_vl_lora_sft
# export_size: 2
# export_device: cpu
# export_legacy_format: false


### model
model_name_or_path: /mnt/workspace/xiaoxi/model_pretrained/qwen_lab/Qwen2-VL-7B-Instruct
adapter_name_or_path: /mnt/workspace/xiaoxi/xiaoxi-all/model_logs/vllm_factory/qwen2_vl-7b/mcot/lora_mcot-interleave-noimglabel-novocot-uniform_2024_12_17_21_25_40
template: qwen2_vl
finetuning_type: lora
new_special_tokens: <IMG>,</IMG>

### export
export_dir: /mnt/workspace/xiaoxi/xiaoxi-all/model_logs/vllm_factory/qwen2_vl-7b/mcot/lora_mcot-interleave-noimglabel-novocot-uniform_2024_12_17_21_25_40/merge/
export_size: 2
export_device: cpu
export_legacy_format: false


# llamafactory-cli export examples/merge_lora/qwen2vl_lora_sft.yaml